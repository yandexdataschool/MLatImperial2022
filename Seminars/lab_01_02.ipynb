{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yandexdataschool/MLatImperial2022/blob/main/Seminars/lab_01_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJR9Y_fbycD2"
      },
      "source": [
        "# Metric methods: KNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -N https://raw.githubusercontent.com/yandexdataschool/MLatImperial2022/main/Seminars/utility.py"
      ],
      "metadata": {
        "id": "c4YK33L10fdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ss_tpwaycD3"
      },
      "outputs": [],
      "source": [
        "import sklearn as skl\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors  import KNeighborsClassifier\n",
        "import numpy as np\n",
        "from  utility import plot_predictions_2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as colors\n",
        "random_state=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Znea4OefycD7"
      },
      "source": [
        "###  How does KNN work on toy oval noisy classes ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXWTV-p7ycD8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "random_state=42\n",
        "num_samples = 300\n",
        "X, y = datasets.make_circles(n_samples=num_samples, factor=0.5, noise=.3,random_state=random_state)\n",
        "\n",
        "X[:,1]=X[:,1]/5\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)\n",
        "plt.scatter(X_train[:,0],X_train[:,1],c=y_train,cmap='bwr')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zTJWNwkycD_"
      },
      "outputs": [],
      "source": [
        "for n in [2,10,20]:\n",
        "    knn_model=KNeighborsClassifier(n_neighbors=n)\n",
        "    knn_model.fit(X_train,y_train)\n",
        "    Y_predicted = knn_model.predict(X_test)\n",
        "    accuracy = accuracy_score(Y_predicted,y_test)\n",
        "    \n",
        "    plot_predictions_2D(\n",
        "        knn_model, X_train, y_train,train=False, task='classification', n=100, cmap=colors.ocean, feature_names=['x1','x2'],alpha=0.5)\n",
        "    plt.title('ovals K=%d test accuracy=%.3f'%(n,accuracy))   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O-eb3kLycEA"
      },
      "source": [
        "### Featues scaling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaUfPBH9ycEC"
      },
      "source": [
        "To scale features, we will use the transformer [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
        "\n",
        "Transformers in `sklearn` have methods `fit` and `transform` (and also `fit_transform`). The `fit` method takes a training sample as input and calculates the necessary values ​​from it (for example, statistics like `StandardScaler`: the mean and standard deviation of each feature). `transform` applies a transformation to the given dataset.\n",
        "\n",
        "The most common scalers:\n",
        "- **StandardScaler()**\n",
        "- **MinMaxScaler()**\n",
        "\n",
        "other scalers see in sklearn.preprocessing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "pcbsxDXtycEE"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "scaler = preprocessing.StandardScaler()\n",
        "\n",
        "X_train_norm = scaler.fit_transform(X_train)\n",
        "X_test_norm=scaler.transform(X_test)\n",
        "for n in [2,20,35]:\n",
        "    knn_model=KNeighborsClassifier(n_neighbors=n)\n",
        "    knn_model.fit(X_train_norm,y_train)\n",
        "    Y_predicted = knn_model.predict(X_test_norm)\n",
        "    accuracy = accuracy_score(Y_predicted,y_test)\n",
        "    plot_predictions_2D(\n",
        "        knn_model, X_train_norm, y_train, task='classification', n=100, cmap=colors.ocean, feature_names=['x1','x2'],alpha=0.5)\n",
        "    plt.title('scaled ovals K=%d test accuracy=%.3f'%(n,accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo51E6HRycEF"
      },
      "source": [
        " Feature scaling improved accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-bPUI8OycEG"
      },
      "outputs": [],
      "source": [
        "#<YOUR TURN>\n",
        "# change scaler in previous cell to another  (MinMaxScaler, RobustScaler or other)\n",
        "# does it give improvement in accuracy_score?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmfGcKBCycEI"
      },
      "source": [
        "## Parameteres search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNmfskCrycEI"
      },
      "outputs": [],
      "source": [
        "from utility import show_param_dependency\n",
        "knn = KNeighborsClassifier(p=2)\n",
        "show_param_dependency(knn, X_train_norm, y_train, X_test_norm, y_test, param_name='n_neighbors', \n",
        "     \n",
        "                      loss_fun='error_rate', param_vals=np.arange(1,100,1), x_label='K')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4RTgCQyycEJ"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=35)\n",
        "show_param_dependency(knn, X_train_norm, y_train, X_test_norm, y_test, param_name='p', \n",
        "     \n",
        "                      loss_fun='error_rate', param_vals=np.arange(1,10,1), x_label='K')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8M-9hOjycEK"
      },
      "outputs": [],
      "source": [
        "#<YOUR TURN>\n",
        "#try to find best combination of p and n_neighbors using these graphs\n",
        "#fit the model with these parameters and make another train-test split, test your model on the new test dataset. did you get similar accuracy?\n",
        "#QUESTION\n",
        "#is it really the best combination of p and n_neighbors?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40bScuFyycEL"
      },
      "source": [
        "### Cross validation score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcTVIl4OycEM"
      },
      "source": [
        "<img src=\"https://docs.splunk.com/images/thumb/e/ee/Kfold_cv_diagram.png/1200px-Kfold_cv_diagram.png\" width=50%>\n",
        "\n",
        "\n",
        "In cross-validation, we divide the training set into $n$ parts (folds). Then we train $n$ models: each model is trained in the absence of a corresponding fold, that is, the $i$-th model is trained on the entire training set, except for objects that are in the $i$-th fold (out-of-fold). After that we measure the quality of the $i$th model on the $i$th fold. Since it did not participate in the training of this model, we will get an \"honest result\". After that, to get the final value of the accuracy (or other) metric, we can average the $n$ values we got.\n",
        "\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question: what's the best number of folds?"
      ],
      "metadata": {
        "id": "r9bPLe10fE27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3uhM5oRycEN"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=35,p=2)\n",
        "cv_scores = cross_val_score(knn_classifier, X_train_norm, y_train, cv=5, scoring=\"accuracy\")\n",
        "print(\"Cross-validation scores : \", cv_scores)\n",
        "print(f\"Cross-validation scores mean:\",cv_scores.mean())\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#<YOUR TURN>\n",
        "#test some n_neighbors (for example, from the list [1,3,8,15,20,35] ) using 'for' cycle on cross-validation\n",
        "#print cross-validation scores for all tested n_neighbors"
      ],
      "metadata": {
        "id": "thK6JIk6f0-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8rVTXwhycEP"
      },
      "source": [
        "##  GridSearchCV\n",
        "<img src=\"https://quantmetry.b-cdn.net/wp-content/uploads/2019/11/corpsTME1.png\" width=\"100%\" />\n",
        "\n",
        "<img src=\"https://www.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/ac3f2f5a-9199-4bb7-8ce6-47e4dc307a0e.png\" width=\"60%\" />\n",
        "\n",
        "\n",
        "*class sklearn.model_selection.GridSearchCV(estimator, param_grid, , scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)*\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UR7ILYaycEP"
      },
      "source": [
        "Grid Search:\n",
        "In Grid Search, the possible values of hyperparameters are defined into the set. Then these sets of possible values of hyperparameters are combined by using Cartesian product and form a multidimensional grid. \n",
        "\n",
        "The grid search then examines all combinations of these hyperparameters\n",
        "\n",
        "For each possible combination of hyperparameters, we train a model on them\n",
        "\n",
        "The hyperparameters associated with the highest accuracy are then returned\n",
        "\n",
        "A grid search is guaranteed to examine all possible combinations of hyperparameters. The problem is that the more hyperparameters you have, the more the number of combinations grows exponentially.\n",
        "If the hyperparameter search space is large, it takes a lot of time and computational power to optimize the hyperparameter.\n",
        "There is no guarantee that these algorithms find local maximum.\n",
        "\n",
        "Grid Search is an exhaustive search method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLsgwC7uycEQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "knn = KNeighborsClassifier()\n",
        "param_grid = {'n_neighbors':[1,3,5,8,10,16,15,20,35,40], 'p':[1,2,3,4,6]}\n",
        "grid_knn = GridSearchCV(knn, param_grid, n_jobs=-1, refit=True)\n",
        "grid_knn.fit(X_train_norm,y_train)\n",
        "print(grid_knn.best_score_, grid_knn.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5-vOQZgycEQ"
      },
      "outputs": [],
      "source": [
        "print(\"Test accuracy:\", accuracy_score(y_test, grid_knn.best_estimator_.predict(X_test_norm)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkSVs5d9ycER"
      },
      "source": [
        "Look at default parametrs of kNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCGASaPQycER"
      },
      "outputs": [],
      "source": [
        "knn_classifier = KNeighborsClassifier()\n",
        "knn_classifier.get_params()\n",
        "\n",
        "f=knn_classifier.set_params(**grid_knn.best_params_)\n",
        "knn_classifier.get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvSOO6GBycES"
      },
      "source": [
        "## Iris species task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMrCX9ThycES"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Iris_flower_data_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIpjZz4NycES"
      },
      "source": [
        "The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbLImJ3uycET"
      },
      "source": [
        "### Spliting dataset into training set and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA6r3SEyycET"
      },
      "outputs": [],
      "source": [
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pd9yQO6dycEU"
      },
      "outputs": [],
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMM_R0JyycEU"
      },
      "source": [
        "### 3D visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnTy8bezycEV"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "fig = plt.figure(1, figsize=(9, 6))\n",
        "ax = Axes3D(fig, elev=48, azim=134)\n",
        "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=y,\n",
        "           cmap=plt.cm.Set1, edgecolor='k', s = X[:, 3]*50)\n",
        "\n",
        "for name, label in [('Virginica', 0), ('Setosa', 1), ('Versicolour', 2)]:\n",
        "    ax.text3D(X[y == label, 0].mean(),\n",
        "              X[y == label, 1].mean(),\n",
        "              X[y == label, 2].mean(), name,\n",
        "              horizontalalignment='center',\n",
        "              bbox=dict(alpha=.5, edgecolor='w', facecolor='w'),size=25)\n",
        "\n",
        "ax.set_title(\"3D visualization\", fontsize=40)\n",
        "ax.set_xlabel(\"Sepal Length [cm]\", fontsize=25)\n",
        "ax.w_xaxis.set_ticklabels([])\n",
        "ax.set_ylabel(\"Sepal Width [cm]\", fontsize=25)\n",
        "ax.w_yaxis.set_ticklabels([])\n",
        "ax.set_zlabel(\"Petal Length [cm]\", fontsize=25)\n",
        "ax.w_zaxis.set_ticklabels([])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qr7d8MPycEV"
      },
      "outputs": [],
      "source": [
        "\n",
        "knn = KNeighborsClassifier()\n",
        "param_grid = {'n_neighbors':[1,3,5,8,10,15,20], 'p':[1,2,4,6]}\n",
        "grid_knn = GridSearchCV(knn, param_grid, n_jobs=-1, refit=True)\n",
        "grid_knn.fit(X_train,y_train)\n",
        "print(grid_knn.best_score_, grid_knn.best_params_)\n",
        "\n",
        "y_predicted = grid_knn.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_predicted)\n",
        "print(f\"accuracy={%.3f}\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se9rCZSKycEW"
      },
      "source": [
        "## Pipeline\n",
        "\n",
        "Now we will use a very convenient class [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html): model training is often represented as a sequence of some actions with training and test sets ( for example, first you need to scale the sample (and for the training sample you need to apply the `fit` method, and for the test sample &mdash; `transform`), and then train / apply the model (for the training `fit`, and for the test &mdash; `predict`) `Pipeline` allows you to store this sequence of steps and correctly handles different types of samples: both training and test.\n",
        "\n",
        " [`Pipeline`](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html):\n",
        "\n",
        " sklearn.pipeline.**Pipeline**(steps, *, memory=None, verbose=False)\n",
        " \n",
        " sklearn.pipeline.**make_pipeline**(*steps, memory=None, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olHQ-bLGycEW"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        " # define the pipeline object.\n",
        "pipeline = Pipeline(steps = [\n",
        "              ('scaler', MinMaxScaler())\n",
        " \n",
        "              ,('KNN',KNeighborsClassifier())\n",
        "           ])\n",
        "\n",
        "parameteres = {'KNN__n_neighbors':[1,2,5,10], 'KNN__p':[1,2,5]}\n",
        "grid = GridSearchCV(pipeline, param_grid=parameteres, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "y_predicted = grid_knn.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_predicted)\n",
        "print(\"accuracy=%.3f\" %accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx3daQ-6ycEX"
      },
      "outputs": [],
      "source": [
        "#<YOUR TURN>\n",
        "# try to change scaler. is there any improvements?\n",
        "# instead of parameter p  try changing 'metric' parameter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nadaraya-Watson kernel regression\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X80dFDHGJ0O9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Ridge regression\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html\n",
        "\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "X = 15 * rng.rand(100, 1)\n",
        "y = np.sin(X).ravel()\n",
        "y += 3 * (0.5 - rng.rand(X.shape[0])) \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "X = 15 * rng.rand(100, 1)\n",
        "y = np.sin(X).ravel()\n",
        "y += 3 * (0.5 - rng.rand(X.shape[0]))\n",
        "\n",
        "#-----------------------\n",
        "\n",
        "kr_linear = KernelRidge()\n",
        "kr_linear.fit(X, y)\n",
        "\n",
        "#-----------------------\n",
        "\n",
        "kr_rbf = KernelRidge(kernel=\"rbf\",gamma=0.2)\n",
        "\n",
        "kr_rbf.fit(X, y)\n",
        "\n",
        "#-----------------------\n",
        "\n",
        "param_grid = {\"gamma\": [1e1,1e0, 1e-1, 1e-2, 1e-3],\n",
        "              \"kernel\":  [\"rbf\"]}\n",
        "\n",
        "kr_grid = GridSearchCV(KernelRidge(), param_grid=param_grid, scoring=\"neg_mean_squared_error\")\n",
        "kr_grid.fit(X,y)\n",
        "\n",
        "#-----------------------\n",
        "\n",
        "y_kr_linear = kr_linear.predict(X_plot)\n",
        "y_kr_rbf = kr_rbf.predict(X_plot)\n",
        "y_kr_grid = kr_grid.predict(X_plot)\n",
        "\n",
        "#-----------------------\n",
        "X_plot = np.linspace(0, 20, 10000)[:, None]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.scatter(X, y, c='k', label='data')\n",
        "plt.plot(X_plot, np.sin(X_plot), color='blue', lw=2, label='True')\n",
        "plt.plot(X_plot, y_kr_rbf, color='brown', lw=2, label='Test kernel')\n",
        "\n",
        "plt.plot(X_plot, y_kr_grid, lw=2, label='(%s)' % kr_grid.best_params_)\n",
        "\n",
        "plt.xlabel('data')\n",
        "plt.ylabel('target')\n",
        "plt.xlim(0, 20)\n",
        "plt.ylim(-4, 4)\n",
        "\n",
        "plt.title('Different Kernels')\n",
        "plt.legend(loc=\"best\",  scatterpoints=1, prop={'size': 15})\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "428xRxaakYa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#<YOUR TURN>\n",
        "#Adjust parameter gamma to make an overfitted model. which gamma values corresponds to underfitted model? Why?\n",
        "# Try polonomial kernel.Is it better than RBF-kernel?\n"
      ],
      "metadata": {
        "id": "UXBf5TpjKVpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7yR48Gg_KR-D"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "lab_01_02.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}